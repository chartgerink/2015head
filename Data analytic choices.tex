\section*{Data analytic choices}
In their original analyses, Head and colleagues use four selection steps that require some justification. These four steps encompass selecting only (i) papers with one Digital Object Identifier (DOI), (ii) papers with non-zero authors, (iii) p-values smaller than .05 (i.e., $<.05$), and (iv) exactly reported p-values (i.e., $p = ...$). Below, I evaluate these four non-standard choices, which could affect results. I argue that (i) and (iii) seem invalid and (ii) and (iv) seem valid.

Choice (i) results in retaining only those papers with one DOI, which seems conservative. Retaining only papers with exactly one DOI results in the elimination of $84,409$ p-values across $13,904$ papers from the full dataset with $2,131,454$ p-values across $243,569$ papers in PubMed. However, no substantive reasons are given for the elimination of papers without a DOI or with multiple DOIs. In fact, eliminating those without DOIs would result in eliminating p-values from perfectly valid articles or older articles, considering DOIs were only initiated in 1999 \cite{Crossre2009}. Upon manual inspection of a small sample, articles with multiple DOIs proved to include links to advanced online publications of the same paper under a different DOI or discussion papers that accompany the original paper. Retaining the papers with zero or $>1$ DOIs therefore seems warranted.

Choice (ii) includes the removal of zero-author papers, which is justifiable. Zero-author papers are most likely editorials, corrections, retractions, etc. These "papers" provide only little information and the p-values they do report are most likely not original p-values, but reproductions provided of p-values reported in another paper. Eliminating these zero-author papers therefore seems a wise choice.

Choice (iii) selects all p-values $<.05$, because the original authors "suspect that many authors do not regard $p=.05$ as significant" \cite{Head2015}. Previous investigation of p-values reported as exactly .05 revealed that $94.3\%$ of 236 cases interpret this as statistically significant \cite{Nuijten2015}. This goes against Head and colleagues their assumption that most researchers do not interpret $p=.05$ as significant, which is why I argue that the selection should be $p\leq.05$ and not $p<.05$.

Choice (iv) retains only the exactly reported p-values, which eliminates potential bias in reported p-values due to the reporting of significance thresholds instead of precise p-values. In other words, if frequencies of inexactly reported results (e.g., $p<.05$) would be included in the analyses, this would artefactually inflate the frequencies, such as the  frequency of the significance threshold .05. This could lead to more "evidence" for p-hacking. Hence, retaining only exactly reported p-values is important to eliminate such artefactual results.